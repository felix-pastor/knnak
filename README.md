These Max for Live devices are one of the outputs of a larger research project done in collaboration with Enric Guaus.
Both devices have been developed in the context of music composition and performance projects (ArInt, nanAI, Physis I and II)
which have been done in collaboration with Edurne Arizu.

You can read about these different projects in the following websites:

https://felixpastor.wordpress.com/

https://enricguaus.wordpress.com/
https://github.com/enricguaus

https://www.edurne-arizu.com/

http://sheepdog.es/



REQUIREMENTS

You must have IRCAM's MUBU package installed in Max for Live.
The devices have been tested in Live 12.



USE

1. Load files in sound bank. This takes some time so look at the Max window for confirmation of slicing.

2. Devices use input to capture incoming signal.

3. This signal is analyzed and the data used to find a matching slice in the loaded audio.

4. Experiment with audio routings and controller mappings.

5. If you find something you like, email us to let us know what making music with AI is.




ACKNOWLEDGMENTS

This work has been partly funded by ESMUC.
